{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STR detection\n",
    "\n",
    "The STR profile is generated using two approaches; one based on the length of the STR regions the other on the  actual sequence.\n",
    "\n",
    "Part 1) Splicing the reads into subreads\n",
    "\n",
    "Part 2A) Mapping the sequence data against a reference\n",
    "\n",
    "Part 2B) Generating a length based profile\n",
    "\n",
    "\n",
    "\n",
    "Part Christophe moet nog een bekeken worden. \n",
    "Zeker het plotten en dergelijke\n",
    "\n",
    "-Obv 3 fouten in primers een locus identificeren. \n",
    "Dit deel is achteraan terug te vinden. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: Splicing read into subreads. \n",
    "\n",
    "-Loading Primers\n",
    "\n",
    "-Loading Sequencing data\n",
    "\n",
    "-Using fuzzy Regex to identify the primers and slice the reads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading primers and sequencing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded primers for 14 loci\n"
     ]
    }
   ],
   "source": [
    "# Load primer sequences (comma separated: str_name,forward_primer_seq,reverse_primer_seq)\n",
    "\n",
    "\n",
    "primerFile = '/home/senne/nanopore/Multiplex/Reference_sequences/STR/primersequences.csv'\n",
    "#Analoog aan SNP primers\n",
    "primerData = {}\n",
    "\n",
    "with open(primerFile) as f:\n",
    "  for l in f:\n",
    "    l = l.strip()\n",
    "    \n",
    "    # Ignore the column header line (should start with a '#')\n",
    "    if l.startswith('#'):\n",
    "      continue\n",
    "    \n",
    "    locus, fPrimer, rPrimer = l.split(',')\n",
    "    primerData[locus] = {'f': fPrimer, 'r': rPrimer}\n",
    "    \n",
    "print('Loaded primers for {} loci'.format(len(primerData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9851 sequences\n"
     ]
    }
   ],
   "source": [
    "# Load sequencing data (ligated loci)\n",
    "#\n",
    "\n",
    "readFile = '/home/senne/nanopore/Multiplex/results/barcode_NB01.fasta'\n",
    "#/home/senne/nanopore/Multiplex/results/barcode_{}.fasta\n",
    "readData = {}\n",
    "\n",
    "with open(readFile) as f:\n",
    "  cnt = 0\n",
    "\n",
    "  for l in f:\n",
    "    cnt += 1\n",
    "    if cnt % 2 == 1:\n",
    "      seqName = l.strip()\n",
    "    elif cnt % 2 == 0:\n",
    "      seqData = l.strip()\n",
    "      readData[seqName] = seqData\n",
    "    else:\n",
    "      continue\n",
    "            \n",
    "print('Loaded {} sequences'.format(len(readData)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a fuzzy regex to splice the reads into subreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "#\n",
    "\n",
    "def reverseComplement(seq):\n",
    "  transTab = str.maketrans('agctyrwskmdvhbAGCTYRWSKMDVHB', 'tcgarywsmkhbdvTCGARYWSMKHBDV')\n",
    "  return seq.translate(transTab)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amelogenine\n",
      "D13S317\n",
      "D16S539\n",
      "D18S51\n",
      "D21S11\n",
      "D3S1358\n",
      "D5S818\n",
      "D7S820\n",
      "D8S1179\n",
      "FGA\n",
      "SE33\n",
      "TH01\n",
      "TPOX\n",
      "vWA\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import regex\n",
    "\n",
    "maxMisMatch  = 3\n",
    "matchPosData = {}\n",
    "ampliconSeq  = []\n",
    "ampLenData   = {}\n",
    "\n",
    "for locus in sorted(primerData):\n",
    "    # DEBUG\n",
    "    #if len(ampLenData)==4: break\n",
    "\n",
    "    # Init\n",
    "    ampLenData[locus] = {}\n",
    "        \n",
    "    # Regex\n",
    "    pFor   = regex.compile('(?e)({}){{e<={}}}'.format(primerData[locus]['f'], maxMisMatch))\n",
    "    pForRc = regex.compile('(?e)({}){{e<={}}}'.format(reverseComplement(primerData[locus]['f']), maxMisMatch))\n",
    "    pRev   = regex.compile('(?e)({}){{e<={}}}'.format(primerData[locus]['r'], maxMisMatch))\n",
    "    pRevRc = regex.compile('(?e)({}){{e<={}}}'.format(reverseComplement(primerData[locus]['r']), maxMisMatch))\n",
    "    \n",
    "    allowedPairs      = [(pFor, pRevRc), (pRev, pForRc)]\n",
    "    allowedPairSense  = ('sense', 'anti-sense')\n",
    "    allowedPairSeqLen = 90\n",
    "    minAmpliconSize   = 50\n",
    "    maxAmpliconSize   = 500\n",
    "    readCnt           = 0\n",
    "    \n",
    "    # Print locus name to indicate progress\n",
    "    print(locus)\n",
    "    \n",
    "    for seq in readData:\n",
    "        readCnt += 1\n",
    "        \n",
    "        # DEBUG\n",
    "        #if readCount == 100: break\n",
    "        \n",
    "        #for pair in allowedPairs:\n",
    "        for i in range(len(allowedPairs)):\n",
    "            pair    = allowedPairs[i]\n",
    "            sense   = allowedPairSense[i]\n",
    "            posList = [[],[]]\n",
    "            \n",
    "            for match in pair[0].finditer(readData[seq]):\n",
    "                b,e = match.span()\n",
    "                posList[0].append(b) # Including the primer\n",
    "                #posList[0].append(e+1) # Excluding the primer, need to refine this if the error is the last nucleotide\n",
    "                \n",
    "            for match in pair[1].finditer(readData[seq]):\n",
    "                b,e = match.span()\n",
    "                posList[1].append(e) # Including the primer\n",
    "                #posList[1].append(b-1) # Excluding the primer, need to refine this if the error is the first nucleotide\n",
    "                \n",
    "            # Retain possible pairs based on amplicon size\n",
    "            if len(posList[0]) and len(posList[1]):\n",
    "                # DEBUG\n",
    "                #print('Found both {} primers in read {}: {}, {}'.format(locus, readCnt, posList[0], posList[1]))\n",
    "                \n",
    "                for p1 in posList[0]:\n",
    "                    for p2 in posList[1]:\n",
    "                        if minAmpliconSize < (p2 - p1) < maxAmpliconSize:\n",
    "                            # We have a potential amplicon?\n",
    "                            #ampLen  = p2 - p1\n",
    "                            sense   = '{} - {} ({})'.format(p1, p2, sense)\n",
    "                            ampSeq  = readData[seq][p1:p2]\n",
    "                            ampLen  = len(ampSeq)\n",
    "                            ampName = '{} {} ({}): {} {}'.format(len(ampliconSeq) + 1, locus, ampLen, sense, seq)\n",
    "                            ampliconSeq.append((ampName, ampSeq))\n",
    "                            \n",
    "                            # Keep amplicon lengths\n",
    "                            if ampLen in ampLenData[locus]:\n",
    "                                ampLenData[locus][ampLen] += 1\n",
    "                            else:\n",
    "                                ampLenData[locus][ampLen] = 1\n",
    "                            \n",
    "                            # DEBUG\n",
    "                            #print('{}, read:{}, amplen={}, {}'.format(locus, readCnt, ampLen, sense))\n",
    "                                                    \n",
    "    \n",
    "# Save potential amplicons\n",
    "outFile = '/home/senne/nanopore/Multiplex/results/STR/STR_BC1-{}mism.fasta'.format(maxMisMatch)\n",
    "with open(outFile, 'w') as f:\n",
    "    for amplicon in ampliconSeq:\n",
    "        f.write('>' + amplicon[0] + '\\n')\n",
    "        f.write(amplicon[1] + '\\n')\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/senne/nanopore/Multiplex/results/STR/\n",
    "grep -c '>' STR_BC8-3mism.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##PART 2A: Mapping against database containing all known alleles\n",
    "\n",
    "-Mapping using BWA and SAM\n",
    "\n",
    "-Extracting the uniquely mapped and once with a mapping score =0 form sam file\n",
    "\n",
    "-Writing to a txt file ready for excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/senne/nanopore/Multiplex/Reference_sequences/STR/STR_database.fasta\n",
      "Number of STRs in reference file:\n",
      "141\n"
     ]
    }
   ],
   "source": [
    "# Init\n",
    "#\n",
    "NBarcode = 1\n",
    "\n",
    "strFile   = '/home/senne/nanopore/Multiplex/Reference_sequences/STR/STR_database.fasta' # REMOVE FIRST LINE IN ORIGINAL FILE (BREAKS FASTA FORMAT)\n",
    "#Dit moet dus de databank zijn van alle bestaande STR allelen voor alle loci. \n",
    "readFile  = '/home/senne/nanopore/Multiplex/results/STR/STR_BC{}-3mism.fasta'.format(NBarcode)\n",
    "#resultDir = '/home/senne/nanopore/Multiplex/results/STR/'\n",
    "fastq_file_name= '/home/senne/nanopore/Multiplex/results/STR/STR_BC{}-3mism.fasta'.format(NBarcode)\n",
    "\n",
    "samfile = '/home/senne/nanopore/Multiplex/results/STR/STR_BCont2d{}.sam'.format(NBarcode)\n",
    "bamfile = '/home/senne/nanopore/Multiplex/results/STR/STR_BC{}ont2d.bam'.format(NBarcode)\n",
    "bambaifile = '/home/senne/nanopore/Multiplex/results/STR/STR_BC{}ont2d.bam.bai'.format(NBarcode)\n",
    "txtfile = '/home/senne/nanopore/Multiplex/results/STR/STR_BC{}ont2d.txt'.format(NBarcode)\n",
    "\n",
    "bwa       = '/opt/tools/bwa-0.7.15'            # v0.7.5\n",
    "samtools  = '/opt/tools/samtools-1.3.1' # v1.3.1\n",
    "bcftools  = '/opt/tools/bcftools-1.3.1' # v1.3.1\n",
    "\n",
    "\n",
    "## oppassen voor de bwa versie!! ##\n",
    "# Check\n",
    "!ls {strFile}\n",
    "print('Number of STRs in reference file:')\n",
    "!grep -c \">\" {strFile}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5541, 188.4722974192384, 168.0, 499, 68.680266923821009)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#SNP and STR data are present in this fasta file\n",
    "hist_array = []\n",
    "hist_arrayG = []\n",
    "hist_arrayA = []\n",
    "hist_arrayC = []\n",
    "hist_arrayT = []\n",
    "with open(fastq_file_name, \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        if line.startswith(b'G'):\n",
    "            read_length = len(line[:-1]) #Last char is \\n\n",
    "            #histogram_data[read_length] += 1\n",
    "            hist_arrayG.append(read_length)\n",
    "with open(fastq_file_name, \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        if line.startswith(b'A'):\n",
    "            read_length = len(line[:-1]) #Last char is \\n\n",
    "            #histogram_data[read_length] += 1\n",
    "            hist_arrayA.append(read_length) \n",
    "with open(fastq_file_name, \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        if line.startswith(b'C'):\n",
    "            read_length = len(line[:-1]) #Last char is \\n\n",
    "            #histogram_data[read_length] += 1\n",
    "            hist_arrayC.append(read_length) \n",
    "with open(fastq_file_name, \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        if line.startswith(b'T'):\n",
    "            read_length = len(line[:-1]) #Last char is \\n\n",
    "            #histogram_data[read_length] += 1\n",
    "            hist_arrayT.append(read_length)\n",
    "\n",
    "hist_array.extend(hist_arrayA)\n",
    "hist_array.extend(hist_arrayC)\n",
    "hist_array.extend(hist_arrayG)\n",
    "hist_array.extend(hist_arrayT)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "len (hist_array), np.mean(hist_array), np.median(hist_array) , max(hist_array), np.std(hist_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping using BWA and SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.15-r1140\n",
      "[main] CMD: /opt/tools/bwa-0.7.15 index /home/senne/nanopore/Multiplex/Reference_sequences/STR/STR_database.fasta\n",
      "[main] Real time: 0.011 sec; CPU: 0.015 sec\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 5541 sequences (1044325 bp)...\n",
      "[M::mem_process_seqs] Processed 5541 reads in 5.398 CPU sec, 5.396 real sec\n",
      "[main] Version: 0.7.15-r1140\n",
      "[main] CMD: /opt/tools/bwa-0.7.15 mem -x ont2d /home/senne/nanopore/Multiplex/Reference_sequences/STR/STR_database.fasta /home/senne/nanopore/Multiplex/results/STR/STR_BC1-3mism.fasta\n",
      "[main] Real time: 5.419 sec; CPU: 5.415 sec\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Map reads to reference sequences\n",
    "#\n",
    "\n",
    "# Build index of the references\n",
    "!{bwa} index {strFile}\n",
    "\n",
    "# Map reads\n",
    "!{bwa} mem -x ont2d {strFile} {readFile} > {samfile}\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Make sorted bam and index\n",
    "#\n",
    "!{samtools} view -Sbu {samfile} | {samtools} sort -o {bamfile} -\n",
    "!{samtools} index {bamfile} {bambaifile}\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the uniquely mapped and once with a mapping score = 0 form sam file\n",
    "\n",
    "Yannick hier nog eens naar laten kijken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd /home/senne/nanopore/Multiplex/results/STR/\n",
    "echo -n \"\" > STR_BC1ont2d.txt\n",
    "for i in \"Amelogenine_X\" \"Amelogenine_Y\" \"D3S1358_13\" \"D3S1358_14\" \"D3S1358_15\" \"D3S1358_16\" \"D3S1358_17\" \"D3S1358_18\" \"D3S1358_19\" \"D21S11_27\" \"D21S11_28\"  \"D21S11_29\" \"D21S11_30\" \"D21S11_31\" \"D21S11_31.2\" \"D21S11_32\" \"D21S11_32.2\" \"D21S11_33.2\" \"TH01_5\" \"TH01_6\" \"TH01_7\" \"TH01_8\" \"TH01_9\" \"TH01_9.3\" \"TH01_10\" \"TH01_11\" \"D16S539_9\" \"D16S539_10\" \"D16S539_11\" \"D16S539_12\" \"D16S539_13\" \"D16S539_14\" \"D16S539_15\" \"D7S820_7\" \"D7S820_8\" \"D7S820_9\" \"D7S820_10\" \"D7S820_11\" \"D7S820_12\" \"D7S820_13\" \"D7S820_14\" \"D13S317_8\" \"D13S317_9\" \"D13S317_10\" \"D13S317_11\" \"D13S317_12\" \"D13S317_13\" \"D13S317_14\" \"D13S818_15\" \"D13S818_16\" \"D18S51_12\" \"D18S51_13\" \"D18S51_14\" \"D18S51_15\" \"D18S51_16\" \"D18S51_17\" \"D18S51_18\" \"D18S51_19\" \"D18S51_20\" \"D5S818_9\" \"D5S818_10\" \"D5S818_11\" \"D5S818_12\" \"D5S818_13\" \"D5S818_14\" \"D5S818_15\" \"D5S818_16\" \"D5S818_17\" \"D5S818_18\" \"D8S1179_8\" \"D8S1179_9\" \"D8S1179_10\" \"D8S1179_12\" \"D8S1179_13\" \"D8S1179_14\" \"D8S1179_15\" \"D8S1179_16\" \"D8S1179_17\" \"D8S1179_18\" \"FGA_18\" \"FGA_19\" \"FGA_20\" \"FGA_21\" \"FGA_22\" \"FGA_23\" \"FGA_24\" \"FGA_25\" \"FGA_26\" \"FGA_27\" \"FGA_28\" \"TPOX_6\" \"TPOX_7\" \"TPOX_8\" \"TPOX_9\" \"TPOX_10\" \"TPOX_11\" \"TPOX_12\" \"TPOX_13\" \"vWA_15\" \"vWA_16\" \"vWA_17\" \"vWA_18\" \"vWA_19\" \"vWA_20\" \"SE33_15\" \"SE33_16\" \"SE33_18\" \"SE33_19\" \"SE33_20\" \"SE33_21\" \"SE33_21.2\"  \"SE33_22.2\" \"SE33_23.2\" \"SE33_24.2\" \"SE33_25.2\" \"SE33_26.2\" \"SE33_27.2\" \"SE33_28.2\" \"SE33_29.2\" \"SE33_30.2\" \"SE33_31.2\"; do \n",
    "    echo -n \"$i;\" >> STR_BC1ont2d.txt\n",
    "    awk '$2 < 1' STR_BCont2d1.sam | awk '$5 > 0'| cut -f3 -d$'\\t'| grep -c $i >> STR_BC1.txt\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Klaar maken voor excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/senne/nanopore/Multiplex/results/test/\n",
    "\n",
    "tr \"_\" \"\\t\" < STR_BC1.txt | tr \";\" \"\\t\" > Mapped_profile_test.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##Amelogenine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##PART 2B: Determining the length of the sequenced subreads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Christophe zorgt voor een fasta met daarin de subreads\n",
    "Hoe krijgen we de reeds gespliced reads in deze pipeline? \n",
    "\n",
    "Daarnaast wordt er nog een histogram gemaakt en gaussiaanse curve opgeplot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All reference sequences should start and end with the primer.\n",
      " This is not the case for locus rs1490413 in your configuration.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "# Analyzing full reads\n",
    "# Reflections\n",
    "#      - Currently generic peak detection and fitting of gaussian curve\n",
    "#      - Future: if enough data, machine learning should be used\n",
    "#      - scikit-learn\n",
    "#      - Literature\n",
    "#      - http://stackoverflow.com/questions/10143905/python-two-curve-gaussian-fitting-with-non-linear-least-squares\n",
    "#      - http://stackoverflow.com/questions/19206332/gaussian-fit-for-python\n",
    "#      - http://bioinformatics.oxfordjournals.org/content/22/17/2059.long\n",
    "#      - http://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.find_peaks_cwt.html\n",
    "%matplotlib inline\n",
    "\n",
    "from itertools import count\n",
    "from math import floor,ceil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "sys.path.append('/home/senne/nanopore')\n",
    "from MyFLq import complement, calculateAlleleNumber, Locus\n",
    "\n",
    "loci = Locus.makeLocusDict(('csv', '/home/senne/nanopore/SNP/known_SNP_sequence/SNP_loci_config2.csv'))\n",
    "exit()\n",
    "#Functions\n",
    "def bpTOfloat(bpLength,locusType):\n",
    "    return int(bpLength)+(int(str(bpLength).split('.')[1]) if '.' in str(bpLength) else 0)/locusType\n",
    "\n",
    "def floatTObp(floatLength,locusType):\n",
    "    return int(floatLength)+(int(str(floatLength).split('.')[1]) if '.' in str(floatLength) else 0)*locusType\n",
    "\n",
    "def calculateOriginalLength(repeats,locusType,refsize,refrepeats):\n",
    "    fullRefRepeats,partialRefRepeat = str(float(refrepeats)).split('.')\n",
    "    fullRepeats,partialRepeat = str(float(repeats)).split('.')\n",
    "    return refsize+locusType*(int(fullRepeats)-int(fullRefRepeats))+(int(partialRepeat)-int(partialRefRepeat))\n",
    "\n",
    "def gaus(x,a,x0,sigma):\n",
    "    return a*np.exp(-(x-x0)**2/(2*sigma**2))\n",
    "\n",
    "def gaus2(x,a_1,x0_1,sigma_1,a_2,x0_2,sigma_2):\n",
    "    return a_1*np.exp(-(x-x0_1)**2/(2*sigma_1**2))+a_2*np.exp(-(x-x0_2)**2/(2*sigma_2**2))\n",
    "\n",
    "# Main class\n",
    "class LigatedRead:\n",
    "    \"\"\"\n",
    "    Class that represents a ligated read of subreads.\n",
    "    Methods allow to extract the subreads for further processing.\n",
    "    The initial read can contain '&', which are divisions between\n",
    "    already known subreads.\n",
    "    \"\"\"\n",
    "    def __init__(self, read, loci,minSize1read=70, maxSize1read=500, maxPrimerErrors=0):\n",
    "        self.read = read\n",
    "        for l in loci:\n",
    "            # Prep loci for use with MyFLq.calculateAlleleNumber\n",
    "            loci[l]['ref_length']       = len(loci[l]['ref_sequence'])\n",
    "            loci[l]['ref_alleleNumber'] = loci[l]['ref_number']\n",
    "            \n",
    "        self.loci                = loci\n",
    "        self.maxSize1read        = maxSize1read\n",
    "        self.minSize1read        = minSize1read\n",
    "        self.maxPrimerErrors     = maxPrimerErrors\n",
    "        self.averagePrimerLength = sum(len(self.loci[l]['ref_forwardP'])+\n",
    "                                       len(self.loci[l]['ref_reverseP'])\n",
    "                                       for l in self.loci)/(2*len(self.loci))\n",
    "        \n",
    "    def processPrimers(self,withPrimerErrors=0):\n",
    "        # Find previous readfragments\n",
    "        self.markpositions('&')\n",
    "        # Primer errors setup\n",
    "        if withPrimerErrors:\n",
    "            # Calculate kmer size\n",
    "            kmerSize = int(self.averagePrimerLength/(1+withPrimerErrors))  # k is half primer length\n",
    "            # Kmer count in expected sequences\n",
    "            self.reference_kmers = {}\n",
    "            for l in self.loci:\n",
    "                for seq in (self.loci[l]['ref_sequence'],complement(self.loci[l]['ref_sequence'])):\n",
    "                    for i in range(len(seq)+1-kmerSize):\n",
    "                        try: self.reference_kmers[seq[i:i+kmerSize]]+=1\n",
    "                        except KeyError: self.reference_kmers[seq[i:i+kmerSize]]=1\n",
    "        # Find primers\n",
    "        for locus in self.loci:\n",
    "            for primertype in ('ref_forwardP','ref_reverseP','ref_forwardP_c','ref_reverseP_c'):\n",
    "                primer = (self.loci[locus][primertype] if not primertype.endswith('_c')\n",
    "                          else complement(self.loci[locus][primertype[:-2]]))\n",
    "                if not withPrimerErrors:\n",
    "                    self.markpositions(primer,locus,primertype)\n",
    "                else:\n",
    "                    primerKmers = {i:primer[i:i+kmerSize] for i in range(0,len(primer)+1-kmerSize,kmerSize)}\n",
    "                    if len(primer)%kmerSize != 0: primerKmers[kmerSize] = primer[-kmerSize:]\n",
    "                    \n",
    "                    # (YG) DEBUG\n",
    "                    print('{} {} {} has {} k-mers (k={})'.format(locus, primertype, primer, len(primerKmers), kmerSize))\n",
    "                    \n",
    "                    for o in primerKmers:\n",
    "                        # (YG) kmer must occur only once in reference sequence (which includes the primer sequences)\n",
    "                        if self.reference_kmers[primerKmers[o]] == 1:\n",
    "                            self.markpositions(primerKmers[o],locus,primertype,offset=o)\n",
    "        # Remove duplicates TODO (make set, then sorted for list)\n",
    "        # Sort on position\n",
    "        self.primerPositions.sort(key = lambda x: x[0])\n",
    "\n",
    "    def markpositions(self,pattern,locus=None,primertype=None,offset=0):\n",
    "        try:\n",
    "            currentPosition = self.read.find(pattern)\n",
    "            while currentPosition != -1:\n",
    "                self.primerPositions.append((currentPosition-offset,locus,primertype))\n",
    "                currentPosition = self.read.find(pattern,currentPosition+1)\n",
    "            \n",
    "        except AttributeError:\n",
    "            self.primerPositions = []\n",
    "            self.markpositions(pattern,locus,primertype)\n",
    "\n",
    "    def extractReads(self,filterArtefacts=True):\n",
    "        self.subreads = []         # [((pos, locus, primertype), (pos, locus, primertype)),]\n",
    "        pp = self.primerPositions  # [(pos, locus, primertype), ]\n",
    "        for i in range(len(pp)-1):\n",
    "            if (self.minSize1read < (pp[i+1][0]-pp[i][0]) < self.maxSize1read and   # 70 < ampliconsize < 500\n",
    "                pp[i][1] == pp[i+1][1] and pp[i][2] and pp[i+1][2] and              # must be same locus, must have primertype\n",
    "                pp[i][2][:6] != pp[i+1][2][:6] and                                  # cannot be both ref_for or both ref_rev\n",
    "                (pp[i][2].endswith('_c') ^ pp[i+1][2].endswith('_c'))):             # one must end with _c\n",
    "                self.subreads.append((pp[i],pp[i+1]))\n",
    "        if filterArtefacts:\n",
    "            nonArtifacts   = {('ref_forwardP', 'ref_reverseP_c'),\n",
    "                              ('ref_reverseP', 'ref_forwardP_c')}\n",
    "            self.artifacts = [s for s in self.subreads if (s[0][2],s[1][2]) not in nonArtifacts]\n",
    "            self.subreads  = [s for s in self.subreads if (s[0][2],s[1][2]) in nonArtifacts]\n",
    "            \n",
    "            # (YG) DEBUG\n",
    "            #print('Found {} subreads, {} artifacts'.format(len(self.subreads), len(self.artifacts)))\n",
    "            #for artifact in self.artifacts:\n",
    "            #  print('Artifact: {}'.format(artifact))\n",
    "\n",
    "    def sortsubreads(self):\n",
    "        # Sort first on length\n",
    "        self.subreads.sort(key=lambda x: (x[1][0]-x[0][0])+len(self.loci[x[1][1]][x[1][2].replace('_c','')]))\n",
    "        # Then on locus\n",
    "        self.subreads.sort(key=lambda x: x[0][1])\n",
    "\n",
    "    def exportReads(self,filename,mode='wt',type='fasta',locus=None,alleleLength=None,maxReads=None):\n",
    "        ci = count(1)\n",
    "        with open(filename,mode) as outfile:\n",
    "            countBlankInSeq = 0\n",
    "            for r in self.subreads:\n",
    "                # (YG) sequence reconstruction: from startpos left primer match to startpos-1 right primer match + sequence of the right primer\n",
    "                seq = self.read[r[0][0]:r[1][0]+len(self.loci[r[1][1]][r[1][2].replace('_c','')])]\n",
    "                if ' ' in seq:\n",
    "                    countBlankInSeq+=1\n",
    "                    continue\n",
    "                if 'reverse' in r[0][2]:\n",
    "                    seq = complement(seq)\n",
    "                    orientation = 'reverse'\n",
    "                else: orientation = 'forward'\n",
    "                outfile.write('>{} {} ({}): {} - {} ({})\\n'.format(next(ci),r[0][1],len(seq),r[0][0],r[1][0],orientation))\n",
    "                outfile.write(seq+'\\n')\n",
    "            if countBlankInSeq: print(countBlankInSeq,\"reads contained blanks and were not exported\")\n",
    "\n",
    "    def histLengths(self):\n",
    "        self.sortsubreads()\n",
    "        self.histLengthData = {}\n",
    "        for subr in self.subreads:\n",
    "            locus = subr[0][1]\n",
    "            # (YG) sequence reconstruction: from startpos left primer match to startpos-1 right primer match + sequence of the right primer\n",
    "            seq = self.read[subr[0][0]:subr[1][0]+len(self.loci[locus][subr[1][2].replace('_c','')])]\n",
    "            #if self.loci[locus]['locusType']:\n",
    "            #    length = float(calculateAlleleNumber(seq,self.loci[locus]))\n",
    "            #else:\n",
    "            length = len(seq)\n",
    "            try:\n",
    "                self.histLengthData[locus][length]+=1\n",
    "            except KeyError:\n",
    "                if locus not in self.histLengthData: self.histLengthData[locus] = {}\n",
    "                self.histLengthData[locus][length]=1\n",
    "\n",
    "    def peakDetection(self,peak_min_width=8,peak_max_width=12,\n",
    "                      peak_max_hight_diff=0.2,\n",
    "                      includeRefProfile=False):\n",
    "        \"\"\"\n",
    "        Work in progress\n",
    "        First draft: peak detection on STR repeat number lenghts,\n",
    "        but should be performed on bp length.\n",
    "\n",
    "        Concept:\n",
    "        - first scipy.signal.find_peaks_cwt for initial peak detection\n",
    "        - select two most prominent peaks, if they are separated minimal distance\n",
    "          and have minimal height difference\n",
    "        - on those 1 or 2 peaks calculate gaussian fit\n",
    "        - use mean and calculated sigma to esitmate likely allele lengths\n",
    "        \"\"\"\n",
    "        \n",
    "        ################################Is dit deel dan alleen nodig voor de piek detectie? #######################\"\n",
    "        from scipy import signal\n",
    "        from scipy.optimize import curve_fit\n",
    "        import numpy as np\n",
    "        \n",
    "        self.profile  = {}\n",
    "        plotDimension = np.sqrt(len(self.histLengthData))\n",
    "        fig,axes      = plt.subplots(ceil(plotDimension),ceil(len(self.histLengthData)/plotDimension),sharex=True,sharey=True)\n",
    "        fig.set_size_inches(2*11.692, 2*8.267)\n",
    "        \n",
    "        for l,ax in zip(sorted(self.histLengthData),\n",
    "                        (ax for row in axes for ax in row)):\n",
    "            locusType = self.loci[l]['locusType']\n",
    "            x         = sorted(self.histLengthData[l])\n",
    "            x_range   = list(range(0,x[-1]+1))\n",
    "            y         = [0 if i not in x else self.histLengthData[l][i] for i in x_range]\n",
    "            peaks     = signal.find_peaks_cwt(y,np.arange(peak_min_width,peak_max_width))\n",
    "            peaks     = [(x_range[p],y[p]) for p in peaks]\n",
    "            peaks.sort(key = lambda x: x[1],reverse = True)\n",
    "            \n",
    "            # Potential peaks\n",
    "            if len(peaks) > 1 and peaks[0][1]*peak_max_hight_diff < peaks[1][1]:\n",
    "                peaks = peaks[:2]\n",
    "            else:\n",
    "                peaks = [peaks[0]]\n",
    "                \n",
    "            # Calculate gaussian fit\n",
    "            x = np.array(x)\n",
    "            y = np.array([self.histLengthData[l][i] for i in x])\n",
    "            ax.plot(x,y,'b+',label=l, marker='.')\n",
    "            try:\n",
    "                if len(peaks) == 1:\n",
    "                    popt,pcov       = curve_fit(gaus,x,y,p0=[max(y),peaks[0][0],peak_min_width])\n",
    "                    self.profile[l] = ((calculateAlleleNumber(' '*int(round(popt[1])),self.loci[l]) if locusType\n",
    "                                        else round(popt[1]), popt[2]/(locusType if locusType else 1)),)\n",
    "                \n",
    "                    ax.plot(x,gaus(x,*popt),'ro:',label='fit1', marker='.')\n",
    "                elif len(peaks) == 2:\n",
    "                    popt,pcov = curve_fit(gaus2,x,y,p0=[max(y),peaks[0][0],peak_min_width,\n",
    "                                                        max(y),peaks[1][0],peak_min_width])\n",
    "                    self.profile[l] = ((calculateAlleleNumber(' '*int(round(popt[1])),self.loci[l]) if locusType\n",
    "                                        else round(popt[1]), popt[2]/(locusType if locusType else 1)),\n",
    "                                       (calculateAlleleNumber(' '*int(round(popt[4])),self.loci[l]) if locusType\n",
    "                                        else round(popt[4]), popt[5]/(locusType if locusType else 1)))\n",
    "                    ax.plot(x,gaus2(x,*popt),'ro:',label='fit2', marker='.')\n",
    "                else: self.profile[l] = None\n",
    "            except RuntimeError:\n",
    "                self.profile[l] = None\n",
    "                \n",
    "            if includeRefProfile and locusType:\n",
    "                # Mark the reference profile allele lengths with vertical green lines\n",
    "                for ra in self.referenceProfile[l]:\n",
    "                    position = calculateOriginalLength(ra, locusType,\n",
    "                                                       self.loci[l]['ref_length'],\n",
    "                                                       self.loci[l]['ref_number'])\n",
    "                    ax.plot((position,position), ax.get_ylim(),'g-')\n",
    "                    \n",
    "            ax.legend()\n",
    "        plt.show(block=False)\n",
    "\n",
    "    def CPI(self,populationFile):\n",
    "        \"\"\"\n",
    "        Calculates combined probability of inclusion, aka\n",
    "        random match probability.\n",
    "        populationFile should be 'csv' formatted, with each line:\n",
    "            <locus name>,<allele size>,<allele frequence>\n",
    "        (without angular brackets)\n",
    "        \"\"\"\n",
    "        # Reprocess self.profile to ranges of alleles\n",
    "        self.profileCI = {}\n",
    "        self.CPI_value = 1\n",
    "        self.populationData = pd.read_csv(populationFile)\n",
    "        self.CPI_unusedLoci = set(self.profile) - set(self.populationData['#Locus name'])        \n",
    "        \n",
    "        for l in self.profile:\n",
    "            if l in self.CPI_unusedLoci: continue\n",
    "            locusAlleles = self.populationData[self.populationData[\n",
    "                self.populationData.columns[0]]==l]\n",
    "            locusAN = locusAlleles[\"Allele number\"]\n",
    "            # TODO float/allele number issue\n",
    "            alleleRanges = [(float(g[0])-g[1],float(g[0])+g[1]) for g in self.profile[l]]\n",
    "            if len(alleleRanges) == 2:\n",
    "                alleleRanges.sort(key = lambda x: x[0])\n",
    "                if alleleRanges[0][1] > alleleRanges[1][0]:\n",
    "                    mean = (alleleRanges[0][1] + alleleRanges[1][0])/2\n",
    "                    alleleRanges = [(alleleRanges[0][0],mean),(mean,alleleRanges[1][1])]\n",
    "                    # TODO check if with 'mean' is best strategy\n",
    "            self.profileCI[l] = alleleRanges\n",
    "            af1 = locusAlleles[(locusAN >= alleleRanges[0][0]) &\n",
    "                               (locusAN < alleleRanges[0][1])][\"Allele Frequency\"].sum()\n",
    "            if len(alleleRanges) == 1:\n",
    "                locusProbability = af1**2\n",
    "            else:\n",
    "                af2 = locusAlleles[(locusAN >= alleleRanges[1][0]) &\n",
    "                                   (locusAN < alleleRanges[1][1])][\"Allele Frequency\"].sum()\n",
    "                locusProbability = 2*af1*af2\n",
    "            self.CPI_value*=locusProbability\n",
    "\n",
    "    def linkReferenceProfile(self,referenceProfileFile):\n",
    "        self.referenceProfile = {}\n",
    "        with open(referenceProfileFile) as inprofile:\n",
    "            for line in inprofile:\n",
    "                if line.startswith('#'): continue\n",
    "                line = line.strip().split(',')\n",
    "                self.referenceProfile[line[0]] = (float(line[1]),float(line[2]))\n",
    "                \n",
    "# Processing reads\n",
    "fastq    = open(\"/home/senne/nanopore/SNP/Nanopore_data/ligatedSNPs.fastq\")\n",
    "c        = count(0)\n",
    "reads    = [line for line in fastq if next(c)%4 == 1]\n",
    "allreads = '&'.join(reads)\n",
    "\n",
    "#ligread = LigatedRead('&'.join(reads),loci)\n",
    "ligread = LigatedRead(allreads,loci)\n",
    "#ligread.linkReferenceProfile('/media/sf_vm_shared/nanopore/Profile9948A')\n",
    "ligread.processPrimers(withPrimerErrors=1)\n",
    "ligread.extractReads()\n",
    "ligread.histLengths()\n",
    "ligread.exportReads('/home/senne/nanopore/SNP/Nanopore_data/separatedLigatedSNPs_minlen.fasta')\n",
    "ligread.peakDetection(includeRefProfile=True)\n",
    "ligread.CPI(populationFile = '/home/senne/nanopore/SNP/Europe_SNP_freq.csv')\n",
    "print(\"RPM value profile:\", ligread.CPI_value)\n",
    "\n",
    "# (YG) Display profile\n",
    "print()\n",
    "print('Estimated profile:')\n",
    "for locus in sorted(ligread.profile):\n",
    "    alleles = ':'.join([str(a[0]) for a in ligread.profile[locus]])\n",
    "    print('  {} {}'.format(locus, alleles))\n",
    "\n",
    "# Calculate an original length\n",
    "#calculateOriginalLength(10.3,\n",
    "                       # ligread.loci['D13S317']['locusType'],\n",
    "                        #ligread.loci['D13S317']['ref_length'],\n",
    "                        #ligread.loci['D13S317']['ref_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded primers for 52 loci\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 21875 sequences\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs1005533\n",
      "rs1015250\n",
      "rs1024116\n",
      "rs1028528\n",
      "rs1029047\n",
      "rs1031825\n",
      "rs10495407\n",
      "rs1335873\n",
      "rs1355366\n",
      "rs1357617\n",
      "rs1360288\n",
      "rs1382387\n",
      "rs1413212\n",
      "rs1454361\n",
      "rs1463729\n",
      "rs1490413\n",
      "rs1493232\n",
      "rs1528460\n",
      "rs1886510\n",
      "rs1979255\n",
      "rs2016276\n",
      "rs2040411\n",
      "rs2046361\n",
      "rs2056277\n",
      "rs2076848\n",
      "rs2107612\n",
      "rs2111980\n",
      "rs251934\n",
      "rs2830795\n",
      "rs2831700\n",
      "rs354439\n",
      "rs717302\n",
      "rs719366\n",
      "rs722098\n",
      "rs727811\n",
      "rs729172\n",
      "rs733164\n",
      "rs735155\n",
      "rs737681\n",
      "rs740910\n",
      "rs763869\n",
      "rs8037429\n",
      "rs826472\n",
      "rs873196\n",
      "rs876724\n",
      "rs891700\n",
      "rs901398\n",
      "rs907100\n",
      "rs914165\n",
      "rs917118\n",
      "rs938283\n",
      "rs964681\n",
      "Done\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
